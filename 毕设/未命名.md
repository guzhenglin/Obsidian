各位老师好，我是2020级电子信息科学与技术专业的顾郑林，我的毕业论文题目是基于 SystemC 的卷积神经网络算法级硬件建模。

我将从研究背景、模型设计和性能等方面做简要陈述，恳请各位老师批评指正。

卷积神经网络是最流行的深度学习架构之一，在计算机视觉领域取得了巨大成功。卷积神经网络的落地应用广泛，包括安防监控、自动驾驶等场景。由于网络模型的复杂化，卷积神经网络在边缘部署时很难满足实际应用中低延迟的要求。因此，设计一种高效的卷积神经网络加速器十分重要。

由于CNN加速器的设计自由度高，计算密集，增加了设计和仿真难度。传统的RTL语言建模周期长，且仿真速度慢。SystemC建模语言抽象层次更高，有利于设计空间探索和快速迭代。

基于SystemC的CNN加速器研究较为广泛，AccTLMSim是周期精确的卷积运算加速器，实现了通信带宽和总线开销的分析。NVDLA是英伟达开源的CNN加速器模型，有SystemC和Verilog两种实现，采用模块化和参数化的设计，为加速器的研究提供了参考。在嵌入式方面，CNN加速器集成在RISV-Ⅴ的SystemC虚拟平台上，能够快速评估不同网络在加速器上的性能。

简单介绍卷积神经网络的结构。除了输入层和输出层，还有四种基本操作，也是加速器需要实现的功能。多通道卷积是计算最密集的层，用于特征提取。常用激活函数有sigmoid、双曲正切、ReLU等，实现非线性映射。池化层主要有最大池化和平均池化两种，用于压缩特征图。全连接将特征数据映射到样本空间，实现与卷积层类似。

卷积神经网络的发展趋势是更深的网络层次。ResNet证明了模型的深度对准确率的直接影响，使得新的CNN模型参数量和计算量不断增加，给加速器的设计提出了更高的要求。

多通道卷积可以用6层循环表示。因为循环嵌套的顺序不影响计算结果，所以可以自由交换位置。多通道卷积的自由度可以分为4类，分别为输出通道数（K）、输出通道的像素数（X’×Y‘）、单个卷积核（R×S）、输出像素点的多个通道（C）。

重写卷积循环，选择K和X’×Y‘并行，即同时计算多个卷积核对应输出通道和每个通道上的多个像素点。数据流动如图所示，左侧为特征图的数据输入，由卷积窗口决定。上方输入权重数据，整列广播。为了复用特征图数据，权重数据向右依次延迟一周期。

加速器的整体架构如图所示，主要分为存储、计算两部分。

存储模块采用多级缓存的设计，旨在保持计算的连续和稳定性。根据是否对数据进行编排以及数据的请求和接受是否为同一模块，缓存可以分为显式和隐式，耦合和解耦。本设计采用显式解耦缓存，由控制器生成地址，直接写入计算模块。FIFO是典型的显式解耦缓存，但无法实现卷积需要的随机重复访问。因此，在FIFO前连接暂存区，构成可重复访问的缓存。

计算单元实现乘加操作，并向右传递数据。设计一种特殊PE，提供选择器，在其他模块的输入和FIFO输入间切换。

最后构成的计算阵列结构如图所示。在阵列的输入和输出增加一层寄存器，实现所有阵列的相互连接。

配置16个32x32的计算阵列连接，以计算VGG16为例。第一层卷积的卷积核有64个，为了降低阵列闲置，选择8x2的排列方式，使计算单元列数与输出通道相同。在特征图较大时，优先匹配输出通道数。计算全连接层时，因为输出为向量，将阵列一维排列，使输出通道尽量大。

激活模块根据配置信息在三种激活函数之间切换，支持加偏置。池化模块由比较器和缓存构成，实现最大池化。以2x2池化为例，4次比较得出结果。由于激活和池化模块使用率较低，仅实现一维SIMD并行。

分别用一个32x32的阵列和16个32x32阵列的组合来计算AlexNet的五层卷积，与传统的MAC阵列和乘累加树对比。因为采用SystemC事务级建模，所以忽略了数据传输的延迟。得益于扩展能力强，阵列组合可以用大量计算单元实现极低的延迟。为了比较计算效率，不考虑DSP单元与PE的差异，得到归一化的加速比。可见，单个阵列的加速效率较高，而阵列组合后显著降低，但对比乘累加树仍有1.1倍的加速。

计算发现，16个计算阵列的加速比仅为单个阵列的7倍左右，在扩展过程中损失较大，即计算资源占用率较低。调整阵列大小为16x16，再次仿真，发现加速比达到10.7。在增加一部分的基础上，扩展能力得到增强。